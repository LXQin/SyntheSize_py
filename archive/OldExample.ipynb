{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88895155",
   "metadata": {},
   "source": [
    "# Use SyntheSize On Radimics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f72b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yannick/GoogleDrive/projects/SyntheSize_py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81334276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yannick/GoogleDrive/projects/SyntheSize_py\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"/Users/kwhiting/Library/CloudStorage/OneDrive-MemorialSloanKetteringCancerCenter/Projects/Li_Xuan_Qin/SyntheSize_py\")\n",
    "print(os.getcwd())\n",
    "\n",
    "# make it point to local version in case of changes\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"synthesize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce9d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannick/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing plotnine...\n",
      "Collecting plotnine\n",
      "  Downloading plotnine-0.15.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in ./.venv/lib/python3.13/site-packages (from plotnine) (3.10.8)\n",
      "Requirement already satisfied: pandas>=2.2.0 in ./.venv/lib/python3.13/site-packages (from plotnine) (2.3.3)\n",
      "Collecting mizani~=0.14.0 (from plotnine)\n",
      "  Downloading mizani-0.14.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./.venv/lib/python3.13/site-packages (from plotnine) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from plotnine) (1.17.0)\n",
      "Collecting statsmodels>=0.14.5 (from plotnine)\n",
      "  Downloading statsmodels-0.14.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=2.2.0->plotnine) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine) (1.17.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.14.5->plotnine)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading plotnine-0.15.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mizani-0.14.3-py3-none-any.whl (133 kB)\n",
      "Downloading statsmodels-0.14.6-cp313-cp313-macosx_11_0_arm64.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels, mizani, plotnine\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [plotnine]━━\u001b[0m \u001b[32m3/4\u001b[0m [plotnine]ls]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mizani-0.14.3 patsy-1.0.2 plotnine-0.15.2 statsmodels-0.14.6\n",
      "pandas is already installed.\n",
      "matplotlib is already installed.\n",
      "seaborn is already installed.\n",
      "xgboost is already installed.\n",
      "numpy is already installed.\n",
      "scipy is already installed.\n"
     ]
    }
   ],
   "source": [
    "# from tools import get_data_metrics, visualize, eval_classifier, vis_classifier\n",
    "from tools import (\n",
    "    get_data_metrics,\n",
    "    visualize,\n",
    "    eval_classifier,\n",
    "    vis_classifier,\n",
    "    heatmap_eval,\n",
    "    UMAP_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9afc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append 'synthesize' and change to that folder\n",
    "# synthesize_path = os.path.join(cwd, \"synthesize\")\n",
    "# os.chdir(synthesize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103dc360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yannick/GoogleDrive/projects/SyntheSize_py\n"
     ]
    }
   ],
   "source": [
    "# confirm\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4b6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and evaluate real vs. generated data:\n",
    "# - Stratified sampling is performed within each group based on the real data\n",
    "# - 'ratio' determines the fraction of real samples to visualize per class\n",
    "# - Heatmaps show the expression patterns of both datasets\n",
    "# - UMAP plots show group-wise structure in 2D space\n",
    "# - If generated data is None, only real data is visualized\n",
    "# visualize(real, groups_real, unique_types, generated, groups_generated, ratio=1, seed=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38efb821",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Case/processed_train_136_full_model_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# === Input Generated Data Description ===\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# - generated.csv has the same columns as real except for samples\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# - The features are already log-transformed\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# - Group labels (0 or 1) are in the last column\u001b[39;00m\n\u001b[32m     13\u001b[39m generated_file_name = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./Case/processed_train_136_full_model_data_epochES_batch01_CVAE1-5_generated.csv\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Please replace it with your actual file path\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m real_raw = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m generated_raw = pd.read_csv(generated_file_name, header=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GoogleDrive/projects/SyntheSize_py/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './Case/processed_train_136_full_model_data.csv'"
     ]
    }
   ],
   "source": [
    "# === Input Real Data Description ===\n",
    "# - 'samples': sample IDs (need to be removed)\n",
    "# - 'groups': class labels (string or numeric; mapped to 0/1 if needed)\n",
    "# - All other columns: raw feature values (e.g., expression counts)\n",
    "# - The feature values in real need to be log-transformed: log2(real + 1)\n",
    "\n",
    "real_file_name = r\"./Case/processed_train_136_full_model_data.csv\"  # Please replace it with your actual file path\n",
    "\n",
    "# === Input Generated Data Description ===\n",
    "# - generated.csv has the same columns as real except for samples\n",
    "# - The features are already log-transformed\n",
    "# - Group labels (0 or 1) are in the last column\n",
    "generated_file_name = r\"./Case/processed_train_136_full_model_data_epochES_batch01_CVAE1-5_generated.csv\"  # Please replace it with your actual file path\n",
    "\n",
    "real_raw = pd.read_csv(real_file_name)\n",
    "generated_raw = pd.read_csv(generated_file_name, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da37c38",
   "metadata": {},
   "source": [
    "Note, the get_data_metrics function expects the real data in raw form (e.g. not log2 transformed) but the generated data in the log transformed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess real and generated datasets. This returns:\n",
    "# - real_data: log2-transformed numeric features from the real dataset\n",
    "# - groups_real: binary-encoded labels (0/1) for the real data\n",
    "# - generated_data: numeric features from the generated dataset\n",
    "# - groups_generated: group labels from the generated data\n",
    "# - unique_types: array of unique class labels (e.g., [0, 1])\n",
    "real, groups_real, generated, groups_generated, unique_types = get_data_metrics(\n",
    "    real_file_name, generated_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1080da",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_eval(real, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs in real data\n",
    "mask_real = ~real.isna().any(axis=1)  # True for rows without NaNs\n",
    "real_clean = real[mask_real]\n",
    "groups_real_clean = groups_real[mask_real]\n",
    "\n",
    "# Drop NaNs in generated data\n",
    "mask_generated = ~generated.isna().any(axis=1)  # True for rows without NaNs\n",
    "generated_clean = generated[mask_generated]\n",
    "groups_generated_clean = groups_generated[mask_generated]\n",
    "\n",
    "UMAP_eval(\n",
    "    dat_real=real_clean,\n",
    "    dat_generated=generated_clean,\n",
    "    groups_real=groups_real_clean,\n",
    "    groups_generated=groups_generated_clean,\n",
    "    legend_pos=\"bottom\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_counts = real.isna().sum()\n",
    "\n",
    "# Display columns that actually have missing values\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_eval(dat_real, dat_generated=None):\n",
    "    r\"\"\"\n",
    "    This function creates a heatmap visualization comparing the generated data and the real data.\n",
    "    dat_generated is applicable only if 2 sets of data is available.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dat_real: pd.DataFrame\n",
    "            the original copy of the data\n",
    "    dat_generated : pd.DataFrame, optional\n",
    "            the generated data\n",
    "\n",
    "    \"\"\"\n",
    "    if dat_generated is None:\n",
    "        # Only plot dat_real if dat_generated is None\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.heatmap(dat_real, cbar=True)\n",
    "        plt.title(\"Real Data\")\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"Samples\")\n",
    "    else:\n",
    "        # Plot both dat_generated and dat_real side by side\n",
    "        fig, axs = plt.subplots(\n",
    "            ncols=2, figsize=(12, 6), gridspec_kw=dict(width_ratios=[0.5, 0.55])\n",
    "        )\n",
    "\n",
    "        sns.heatmap(dat_generated, ax=axs[0], cbar=False)\n",
    "        axs[0].set_title(\"Generated Data\")\n",
    "        axs[0].set_xlabel(\"Features\")\n",
    "        axs[0].set_ylabel(\"Samples\")\n",
    "\n",
    "        sns.heatmap(dat_real, ax=axs[1], cbar=True)\n",
    "        axs[1].set_title(\"Real Data\")\n",
    "        axs[1].set_xlabel(\"Features\")\n",
    "        axs[1].set_ylabel(\"Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    real_data,\n",
    "    groups_real,\n",
    "    unique_types,\n",
    "    generated_data=None,\n",
    "    groups_generated=None,\n",
    "    ratio=1,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize real and optionally generated data using heatmap and UMAP projections.\n",
    "\n",
    "    Supports both binary and multi-class settings. For each class, samples from both datasets\n",
    "    are drawn based on real data class proportions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    real_data : pd.DataFrame\n",
    "        Feature matrix of real dataset (without 'groups' column).\n",
    "    groups_real : pd.Series\n",
    "        Group labels for the real dataset.\n",
    "    unique_types : array-like\n",
    "        Unique class labels to iterate over.\n",
    "    generated_data : pd.DataFrame, optional\n",
    "        Feature matrix of generated dataset (same columns as real_data).\n",
    "    groups_generated : pd.Series, optional\n",
    "        Group labels for the generated dataset.\n",
    "    ratio : float, default=1\n",
    "        Sampling ratio within each class (based on real data).\n",
    "    seed : int, default=42\n",
    "        Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    real_indices = []\n",
    "    generated_indices = []\n",
    "\n",
    "    for group in unique_types:\n",
    "        # Sample from real\n",
    "        real_idx = np.where(groups_real == group)[0]\n",
    "        n_sample = round(len(real_idx) * ratio)\n",
    "        sampled_real = np.random.choice(real_idx, size=n_sample, replace=False)\n",
    "        real_indices.extend(sampled_real.tolist())\n",
    "\n",
    "        # Sample from generated if provided\n",
    "        if generated_data is not None and groups_generated is not None:\n",
    "            gen_idx = np.where(groups_generated == group)[0]\n",
    "            if len(gen_idx) < n_sample:\n",
    "                raise ValueError(\n",
    "                    f\"Not enough samples in generated data for group '{group}'\"\n",
    "                )\n",
    "            sampled_gen = np.random.choice(gen_idx, size=n_sample, replace=False)\n",
    "            generated_indices.extend(sampled_gen.tolist())\n",
    "\n",
    "    # Heatmap\n",
    "    if generated_data is None:\n",
    "        heatmap_eval(dat_real=real_data.iloc[real_indices, :])\n",
    "    else:\n",
    "        heatmap_eval(\n",
    "            dat_real=real_data.iloc[real_indices, :],\n",
    "            dat_generated=generated_data.iloc[generated_indices, :],\n",
    "        )\n",
    "\n",
    "        # UMAP\n",
    "        # UMAP_eval(\n",
    "        #     dat_real=real_data.iloc[real_indices, :],\n",
    "        #     dat_generated=generated_data.iloc[generated_indices, :],\n",
    "        #     groups_real=groups_real.iloc[real_indices],\n",
    "        #     groups_generated=groups_generated.iloc[generated_indices],\n",
    "        #     legend_pos=\"bottom\"\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    real, groups_real, unique_types, generated, groups_generated, ratio=1, seed=88\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c85afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and evaluate real vs. generated data:\n",
    "# - Stratified sampling is performed within each group based on the real data\n",
    "# - 'ratio' determines the fraction of real samples to visualize per class\n",
    "# - Heatmaps show the expression patterns of both datasets\n",
    "# - UMAP plots show group-wise structure in 2D space\n",
    "# - If generated data is None, only real data is visualized\n",
    "visualize(\n",
    "    real, groups_real, unique_types, generated, groups_generated, ratio=1, seed=88\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we only have the real samples...\n",
    "visualize(real, groups_real, unique_types, ratio=1, seed=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaece9",
   "metadata": {},
   "source": [
    "# PRADSubtype classification accurary multiple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate sample sizes ranging from 'step' to the full size of real data\n",
    "step = len(real) // 30\n",
    "n_candidate = np.arange(step, len(real) + 1, step)\n",
    "n_candidate = n_candidate[(n_candidate >= 12) & (n_candidate <= len(real))]\n",
    "\n",
    "# Define target sizes that go beyond the candidate range (extrapolation)\n",
    "n_target = np.array([n_candidate[-1] + x * step for x in range(1, 4)])\n",
    "print(f\"n_candidate: {n_candidate}\\nn_target: {n_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b419b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier for real data\n",
    "metric_real = eval_classifier(\n",
    "    whole_generated=real,\n",
    "    whole_groups=groups_real,\n",
    "    n_candidate=n_candidate,\n",
    "    n_draw=30,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "# Save the results to csv file if necessary\n",
    "metric_real.to_csv(f\"LIHCSubtypeFamInd_DESeq_metric_real.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier for generated data\n",
    "metric_generated = eval_classifier(\n",
    "    whole_generated=generated,\n",
    "    whole_groups=groups_generated,\n",
    "    n_candidate=n_candidate,\n",
    "    n_draw=30,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "# Save the results to csv file if necessary\n",
    "metric_generated.to_csv(f\"LIHCSubtypeFamInd_DESeq_metric_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have already saved the results\n",
    "# metric_real = pd.read_csv(f'PRADSubtype_icd_o_3_histology_metric_real.csv',header = 0)\n",
    "# metric_generated = pd.read_csv(f'PRADSubtype_icd_o_3_histology_metric_generated.csv',header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db70a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classifier performance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p_acc = vis_classifier(\n",
    "    metric_generated=metric_generated,\n",
    "    metric_real=metric_real,\n",
    "    metric_name=\"f1_score\",\n",
    "    n_target=n_target,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_file_name = r\"./Case/LIHCSubtypeFamInd_test74.csv\"\n",
    "generated_file_name = (\n",
    "    r\"./Case/LIHCSubtypeFamInd_train294_epochES_batch01_CVAE1-10_generated.csv\"\n",
    ")\n",
    "real, groups_real, generated, groups_generated, unique_types = get_data_metrics(\n",
    "    real_file_name, generated_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd025b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = len(real) // 30\n",
    "n_candidate = np.arange(step, len(real) + 1, step)\n",
    "n_candidate = n_candidate[(n_candidate >= 12) & (n_candidate <= len(real))]\n",
    "\n",
    "# Define target sizes that go beyond the candidate range (extrapolation)\n",
    "n_target = np.array([n_candidate[-1] + x * step for x in range(1, 4)])\n",
    "print(f\"n_candidate: {n_candidate}\\nn_target: {n_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_real = eval_classifier(\n",
    "    whole_generated=real,\n",
    "    whole_groups=groups_real,\n",
    "    n_candidate=n_candidate,\n",
    "    n_draw=30,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "# Save the results to csv file if necessary\n",
    "metric_real.to_csv(f\"LIHCSubtypeFamInd_metric_real.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_generated = eval_classifier(\n",
    "    whole_generated=generated,\n",
    "    whole_groups=groups_generated,\n",
    "    n_candidate=n_candidate,\n",
    "    n_draw=30,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "# Save the results to csv file if necessary\n",
    "metric_generated.to_csv(f\"LIHCSubtypeFamInd_metric_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p_acc = vis_classifier(\n",
    "    metric_generated=metric_generated,\n",
    "    metric_real=metric_real,\n",
    "    metric_name=\"f1_score\",\n",
    "    n_target=n_target,\n",
    "    save=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
